# ××“×¨×™×š ×™×™×©×•× ××œ× - Sign Language Recognition

××“×¨×™×š ×©×œ×‘-××—×¨-×©×œ×‘ ×œ×™×™×©×•× ×”×¤×¨×•×™×§×˜ ×•××™××•×Ÿ ×”××•×“×œ.

## ×ª×•×›×Ÿ ×¢× ×™×™× ×™×

1. [×”×›× ×ª ×”×¡×‘×™×‘×”](#1-×”×›× ×ª-×”×¡×‘×™×‘×”)
2. [×—×™×œ×•×¥ Keypoints](#2-×—×™×œ×•×¥-keypoints)
3. [×™×¦×™×¨×ª Dataset](#3-×™×¦×™×¨×ª-dataset)
4. [××™××•×Ÿ ×”××•×“×œ](#4-××™××•×Ÿ-×”××•×“×œ)
5. [×©×™××•×© ×‘××•×“×œ](#5-×©×™××•×©-×‘××•×“×œ)
6. [××™××•×Ÿ ×‘-Google Colab](#6-××™××•×Ÿ-×‘-google-colab)

---

## 1. ×”×›× ×ª ×”×¡×‘×™×‘×”

### 1.1 ×”×ª×§× ×ª Python

```bash
# ×‘×“×•×§ ×©×™×© Python 3.8+
python --version

# ×× ×œ×, ×”×•×¨×“ ×-python.org
```

### 1.2 ×™×¦×™×¨×ª Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 1.3 ×”×ª×§× ×ª ×ª×œ×•×™×•×ª

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**×ª×œ×•×™×•×ª ×¢×™×§×¨×™×•×ª:**
- `opencv-python` - ×¢×™×‘×•×“ ×•×™×“××•
- `mediapipe` - ×–×™×”×•×™ ×™×“×™×™×
- `tensorflow` - ××™××•×Ÿ ××•×“×œ
- `numpy`, `pandas`, `scikit-learn` - ×¢×™×‘×•×“ × ×ª×•× ×™×

---

## 2. ×—×™×œ×•×¥ Keypoints

### 2.1 ×”×›× ×ª ×¡×¨×˜×•× ×™×

×”× ×™×— ××ª ×”×¡×¨×˜×•× ×™× ×‘×ª×™×§×™×™×”:
```
Data/rawVideos/
â”œâ”€â”€ Hello/
â”‚   â”œâ”€â”€ Hello01.mp4
â”‚   â”œâ”€â”€ Hello02.mp4
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Yes/
â””â”€â”€ ...
```

### 2.2 ×”×¨×¦×ª ×—×™×œ×•×¥

```bash
python scripts/extract_keypoints.py
```

**××” ×§×•×¨×”:**
1. ×”×¡×§×¨×™×¤×˜ ×¢×•×‘×¨ ×¢×œ ×›×œ ×”×¡×¨×˜×•× ×™×
2. ××¤×™×§ keypoints ×‘×××¦×¢×•×ª MediaPipe
3. ×× ×¨××œ ××ª ×”-keypoints (××™×§×•×, ×’×•×“×œ, ×¦×“ ×”×™×“)
4. ×©×•××¨ ×›-`.npy` files ×‘-`Data/Keypoints/rawVideos/`

**×¤×•×¨××˜ × ×ª×•× ×™×:**
- ×›×œ ×¡×¨×˜×•×Ÿ â†’ ×§×•×‘×¥ `.npy`
- ×¦×•×¨×”: `(num_frames, 2, 21, 3)`
  - `num_frames`: ××¡×¤×¨ frames
  - `2`: ××¡×¤×¨ ×™×“×™×™× (×ª××™×“ 2 slots)
  - `21`: keypoints ×œ×›×œ ×™×“
  - `3`: ×§×•××•×¨×“×™× ×˜×•×ª (x, y, z)

**× ×¨××•×œ:**
- âœ… Wrist ×‘-(0,0,0) - ×œ× ×ª×œ×•×™ ×‘××™×§×•×
- âœ… Scale ×œ×¤×™ ×’×•×“×œ ×”×™×“ - ×œ× ×ª×œ×•×™ ×‘×’×•×“×œ
- âœ… Mirror left/right - ×œ× ×ª×œ×•×™ ×‘×¦×“ ×”×™×“
- âœ… Rotation alignment - ×œ× ×ª×œ×•×™ ×‘×›×™×•×•×Ÿ

### 2.3 ×‘×“×™×§×ª ×ª×•×¦××•×ª

```bash
# ×‘×“×•×§ ×›××” ×§×‘×¦×™× × ×•×¦×¨×•
python -c "from pathlib import Path; files = list(Path('Data/Keypoints/rawVideos').rglob('*.npy')); print(f'Total files: {len(files)}')"
```

---

## 3. ×™×¦×™×¨×ª Dataset

### 3.1 ×™×¦×™×¨×ª CSV

```bash
python scripts/create_dataset_csv.py
```

**××” ×§×•×¨×”:**
1. ××•×¦× ××ª ×›×œ ×§×‘×¦×™ `.npy`
2. ××—×œ×§ ×œ-train/val/test (60%/20%/20%)
3. ×™×•×¦×¨ `Data/Labels/dataset.csv`

**×¤×•×¨××˜ CSV:**
```csv
path,label,split
keypoints/GoodBye/goodbye02.npy,GOODBYE,train
keypoints/Hello/hello01.npy,HELLO,test
...
```

### 3.2 ×‘×“×™×§×ª Dataset

```bash
# ×‘×“×•×§ ×›××” samples ×‘×›×œ split
python -c "import pandas as pd; df = pd.read_csv('Data/Labels/dataset.csv'); print(df.groupby(['label', 'split']).size())"
```

---

## 4. ××™××•×Ÿ ×”××•×“×œ

### 4.1 ××™××•×Ÿ ××§×•××™ (×× ×™×© GPU)

```bash
python scripts/train_model.py \
    --csv Data/Labels/dataset.csv \
    --keypoints-dir Data/Keypoints/rawVideos \
    --output-dir models \
    --batch-size 32 \
    --epochs 100 \
    --gru-units 128 \
    --num-gru-layers 2 \
    --dropout 0.3 \
    --learning-rate 0.001 \
    --patience 10
```

**×¤×¨××˜×¨×™×:**
- `--batch-size`: ×’×•×“×œ batch (32 ××•××œ×¥)
- `--epochs`: ××¡×¤×¨ ××§×¡×™××œ×™ ×©×œ epochs
- `--gru-units`: ××¡×¤×¨ ×™×—×™×“×•×ª ×‘-GRU (128 ××•××œ×¥)
- `--num-gru-layers`: ××¡×¤×¨ ×©×›×‘×•×ª GRU (2 ××•××œ×¥)
- `--dropout`: Dropout rate (0.3 ××•××œ×¥)
- `--learning-rate`: Learning rate (0.001 ××•××œ×¥)
- `--patience`: Early stopping patience (10 ××•××œ×¥)

### 4.2 ××” ×§×•×¨×” ×‘××™××•×Ÿ

1. **×˜×¢×™× ×ª × ×ª×•× ×™×**: ×˜×•×¢×Ÿ keypoints ××”-CSV
2. **Preprocessing**: Padding sequences ×œ××•×ª×• ××•×¨×š
3. **××™××•×Ÿ**: GRU model ×¢× callbacks:
   - ModelCheckpoint - ×©×•××¨ ××ª ×”××•×“×œ ×”×˜×•×‘ ×‘×™×•×ª×¨
   - EarlyStopping - ×¢×•×¦×¨ ×× ××™×Ÿ ×©×™×¤×•×¨
   - ReduceLROnPlateau - ××§×˜×™×Ÿ learning rate

### 4.3 ×ª×•×¦××•×ª

×œ××—×¨ ××™××•×Ÿ, ×‘×ª×™×§×™×™×ª `models/run_TIMESTAMP/`:
- `best_model.keras` - ×”××•×“×œ ×”×˜×•×‘ ×‘×™×•×ª×¨
- `final_model.keras` - ×”××•×“×œ ××”××™××•×Ÿ ×”××—×¨×•×Ÿ
- `label_mapping.json` - ××™×¤×•×™ labels
- `training_history.json` - ×”×™×¡×˜×•×¨×™×™×ª ××™××•×Ÿ
- `test_results.json` - ×ª×•×¦××•×ª ×¢×œ test set

---

## 5. ×©×™××•×© ×‘××•×“×œ

### 5.1 ×—×™×–×•×™ ××¡×¨×˜×•×Ÿ

```bash
python scripts/predict.py \
    --model models/run_YYYYMMDD_HHMMSS/best_model.keras \
    --video path/to/video.mp4
```

### 5.2 ×—×™×–×•×™ ×-keypoints

```bash
python scripts/predict.py \
    --model models/run_YYYYMMDD_HHMMSS/best_model.keras \
    --keypoints Data/Keypoints/rawVideos/Hello/Hello01.npy
```

### 5.3 ×©××™×¨×ª ×ª×•×¦××•×ª

```bash
python scripts/predict.py \
    --model models/run_YYYYMMDD_HHMMSS/best_model.keras \
    --video video.mp4 \
    --output results.json
```

---

## 6. ××™××•×Ÿ ×‘-Google Colab

### 6.1 ×¤×ª×™×—×ª Notebook ×‘-Colab

**×”×“×¨×š ×”×§×œ×” ×‘×™×•×ª×¨:**

1. ×œ×š ×œ-[Google Colab](https://colab.research.google.com)
2. File â†’ Open notebook â†’ GitHub
3. ×”×–×Ÿ: `MAya0M/SignLanguage-Recognition`
4. ×‘×—×¨: `notebooks/SignLanguage_Training.ipynb`

**××• ×¤×©×•×˜ ×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨ "Open in Colab" ×‘-README!**

×¨××” [COLAB_AUTOMATIC_SETUP.md](COLAB_AUTOMATIC_SETUP.md) ×œ××“×¨×™×š ××¤×•×¨×˜.

### 6.2 ×”×’×“×¨×ª GPU

1. **Runtime â†’ Change runtime type**
2. **Hardware accelerator â†’ GPU (T4)**
3. **Save**

### 6.3 ×”×¢×œ××ª × ×ª×•× ×™×

**×“×¨×š 1: Google Drive (××•××œ×¥)**
- ×”×¢×œ×” ××ª `sign_language_data.tar.gz` ×œ-Google Drive
- Mount Drive ×‘-Colab
- ×”×¢×ª×§ ××ª ×”×§×•×‘×¥ ×œ×ª×™×§×™×™×ª ×”×¤×¨×•×™×§×˜

**×“×¨×š 2: ×™×©×™×¨×•×ª ×‘-Colab**
- Files â†’ Upload to session storage
- ×”×¢×œ×” ××ª ×”×§×‘×¦×™× ×”× ×“×¨×©×™×

×œ××“×¨×™×š ××¤×•×¨×˜, ×¨××” [COLAB_UPLOAD_GUIDE.md](COLAB_UPLOAD_GUIDE.md)

### 6.4 ××™××•×Ÿ

×¤×©×•×˜ **Runtime â†’ Run all** - ×”×›×œ ××•×˜×•××˜×™!

×”××•×“×œ ×™×ª×××Ÿ ×•×™×™×©××¨ ×‘×ª×™×§×™×™×ª `models/`.

---

## ×˜×™×¤×™× ×œ×©×™×¤×•×¨

### 1. ×”×’×“×œ×ª Dataset

- ××•×¡×£ ×™×•×ª×¨ ×¡×¨×˜×•× ×™× ×œ×›×œ ××™×œ×”
- ×•×¨×™××¦×™×•×ª: ×–×•×•×™×•×ª ×©×•× ×•×ª, ×× ×©×™× ×©×•× ×™×
- Data Augmentation: rotations, scaling

### 2. ×©×™×¤×•×¨ ×”××•×“×œ

- ×”×’×“×œ `gru-units` (256, 512)
- ×”×•×¡×£ ×©×›×‘×•×ª GRU (`--num-gru-layers 3`)
- × ×¡×” Attention mechanisms
- × ×¡×” Transformer ×‘××§×•× GRU

### 3. ××•×¤×˜×™××™×–×¦×™×”

- Mixed Precision Training
- Gradient Accumulation
- Learning Rate Scheduling

---

## Troubleshooting

### ×‘×¢×™×•×ª × ×¤×•×¦×•×ª

**Out of Memory:**
```bash
# ×”×§×˜×Ÿ batch size
--batch-size 16
```

**Overfitting:**
```bash
# ×”×’×“×œ dropout
--dropout 0.5

# ×”×•×¡×£ regularization
```

**Underfitting:**
```bash
# ×”×’×“×œ ××¡×¤×¨ layers/units
--gru-units 256
--num-gru-layers 3
```

**×§×‘×¦×™× ×œ× × ××¦××™×:**
```bash
# ×‘×“×•×§ × ×ª×™×‘×™×
python utils/verify_csv_files.py
```

---

## Workflow ××œ×

```bash
# 1. ×—×™×œ×•×¥ keypoints
python scripts/extract_keypoints.py

# 2. ×™×¦×™×¨×ª dataset
python scripts/create_dataset_csv.py

# 3. ××™××•×Ÿ (××§×•××™ ××• Google Colab)
python scripts/train_model.py --csv Data/Labels/dataset.csv

# 4. ×—×™×–×•×™
python scripts/predict.py --model models/.../best_model.keras --video test.mp4
```

---

## Next Steps

1. âœ… ×”×›×Ÿ ××ª ×”×¡×‘×™×‘×”
2. âœ… ×—×œ×¥ keypoints ××”×¡×¨×˜×•× ×™×
3. âœ… ×¦×•×¨ dataset CSV
4. âœ… ×××Ÿ ××ª ×”××•×“×œ (××§×•××™ ××• Google Colab)
5. âœ… ×‘×“×•×§ ××ª ×”××•×“×œ ×¢×œ ×¡×¨×˜×•× ×™× ×—×“×©×™×
6. ğŸ”„ ×©×¤×¨ ××ª ×”××•×“×œ ×œ×¤×™ ×”×¦×•×¨×š

**×‘×”×¦×œ×—×”! ğŸš€**

