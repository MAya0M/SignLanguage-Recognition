# שיפורי האימון - Training Improvements

## מה שונה?

עשיתי שיפורים משמעותיים כדי שהמודל ילמד טוב יותר:

### 1. **Learning Rate נמוך יותר** (0.0001 במקום 0.001)
- **למה:** Learning rate גבוה מדי גורם למודל לקפוץ מעל המינימום ולא להתכנס
- **תוצאה:** אימון יציב יותר, התכנסות טובה יותר

### 2. **Batch Size קטן יותר** (16 במקום 32)
- **למה:** עם 130 samples ב-train, batch size קטן יותר נותן יותר gradient updates
- **תוצאה:** המודל לומד מהר יותר ומתכנס טוב יותר

### 3. **מודל גדול יותר**
- **GRU Units:** 256 במקום 128
- **GRU Layers:** 3 במקום 2
- **למה:** יותר capacity למודל ללמוד דפוסים מורכבים
- **תוצאה:** המודל יכול ללמוד יותר features

### 4. **Dropout גבוה יותר** (0.4 במקום 0.3)
- **למה:** מונע overfitting עם מודל גדול יותר
- **תוצאה:** המודל כללי יותר, עובד טוב יותר על נתונים חדשים

### 5. **Patience גדול יותר** (25 במקום 10)
- **למה:** המודל צריך יותר זמן ללמוד, במיוחד עם learning rate נמוך
- **תוצאה:** המודל לא עוצר מוקדם מדי

### 6. **יותר Epochs** (200 במקום 100)
- **למה:** נותן למודל יותר זמן להתכנס
- **תוצאה:** המודל יכול להגיע ל-better accuracy

### 7. **Early Stopping משופר**
- **Monitor:** `val_loss` במקום `val_accuracy`
- **למה:** Loss יותר רגיש לשינויים קטנים
- **תוצאה:** המודל עוצר בזמן הנכון

### 8. **Data Normalization**
- **מה:** Normalization של הנתונים (zero mean, unit variance)
- **למה:** עוזר למודל ללמוד מהר יותר ויציב יותר
- **תוצאה:** Training מהיר יותר ויציב יותר

### 9. **Batch Normalization**
- **מה:** הוספת Batch Normalization ל-dense layers
- **למה:** עוזר למודל ללמוד מהר יותר
- **תוצאה:** Training מהיר יותר ויציב יותר

### 10. **ReduceLROnPlateau משופר**
- **Patience:** 8 במקום 5
- **Min LR:** 1e-8 במקום 1e-7
- **Cooldown:** 3 epochs
- **למה:** נותן למודל יותר זמן לפני הפחתת learning rate
- **תוצאה:** המודל לא מפחית learning rate מוקדם מדי

## איך להשתמש?

פשוט הרץ את הנוטבוק ב-Colab - כל השיפורים כבר מובנים!

```python
# זה כבר מעודכן בנוטבוק:
!python scripts/train_model.py --csv Data/Labels/dataset.csv \
  --keypoints-dir Data/Keypoints/rawVideos \
  --output-dir models \
  --batch-size 16 \
  --epochs 200 \
  --gru-units 256 \
  --num-gru-layers 3 \
  --dropout 0.4 \
  --learning-rate 0.0001 \
  --patience 25
```

## מה לצפות?

1. **Training יקח יותר זמן** - אבל המודל ילמד טוב יותר
2. **Accuracy יעלה לאט** - אבל יציב יותר
3. **המודל לא יעצור מוקדם** - יקבל יותר זמן ללמוד
4. **תוצאות טובות יותר** - accuracy גבוה יותר בסוף

## טיפים

1. **ודא שה-CSV מעודכן** - צריך 226 samples, לא 129!
2. **השתמש ב-GPU** - Training יקח הרבה זמן ב-CPU
3. **תן למודל זמן** - אל תעצור את האימון מוקדם
4. **בדוק את ה-validation accuracy** - זה מה שחשוב, לא training accuracy

## אם המודל עדיין לא לומד

אז הבעיה היא בנתונים, לא במודל:
1. **ודא שה-CSV מעודכן** - 226 samples
2. **ודא שכל הקבצים קיימים** - כל ה-.npy files
3. **בדוק את הנתיבים** - שהנתיבים ב-CSV תואמים למיקום הקבצים

