# הסבר על המודל - GRU לזיהוי שפת סימנים

## המודל שנבחר: **GRU (Gated Recurrent Unit)**

### למה GRU?

**GRU** הוא סוג של **Recurrent Neural Network (RNN)** שמתאים מאוד לזיהוי sequences של תנועות.

**יתרונות:**
- ✅ **מתאים ל-sequences** - זוכר מידע מתנועות קודמות
- ✅ **יעיל** - יותר מהיר מ-LSTM אבל עדיין חזק
- ✅ **טוב לתנועות** - מבין את הקשר בין frames בסרטון
- ✅ **לא מסובך** - קל לאימון ולהבנה

---

## איך זה עובד? - תהליך מלא

### שלב 1: חילוץ Keypoints מהסרטון

```
סרטון (MP4)
    ↓
MediaPipe Hand Landmarker
    ↓
Keypoints: (num_frames, 2, 21, 3)
- num_frames: מספר frames
- 2: שתי ידיים
- 21: keypoints לכל יד
- 3: קואורדינטות (x, y, z)
```

**דוגמה:**
- סרטון של 30 frames
- כל frame: 2 ידיים × 21 keypoints × 3 קואורדינטות = 126 features
- **Input**: (30, 126) - sequence של 30 frames, כל אחד עם 126 features

### שלב 2: נרמול

הנרמול מבטיח שהמודל לא תלוי ב:
- **מיקום היד** - Wrist מתורגם ל-(0,0,0)
- **גודל היד** - Scale לפי גודל היד
- **צד היד** - Left/Right hand → normalized ל-right hand
- **כיוון** - Rotation alignment

**תוצאה**: Keypoints מנורמלים, מוכנים לאימון

### שלב 3: הכנה לאימון

```
Keypoints: (30, 2, 21, 3)
    ↓
Flatten: (30, 126)
    ↓
Padding: (max_length, 126)  # כל sequences לאותו אורך
    ↓
Ready for GRU!
```

### שלב 4: ארכיטקטורת המודל

```
Input: (sequence_length, 126 features)
    ↓
┌─────────────────────────────────┐
│  GRU Layer 1 (128 units)       │  ← זוכר מידע מתנועות קודמות
│  - return_sequences=True        │
└─────────────────────────────────┘
    ↓
┌─────────────────────────────────┐
│  GRU Layer 2 (128 units)       │  ← עוד שכבה לעיבוד עמוק יותר
│  - return_sequences=False       │
└─────────────────────────────────┘
    ↓
┌─────────────────────────────────┐
│  Dense Layer 1 (128 units)    │  ← עיבוד נוסף
│  - ReLU activation              │
│  - Dropout (0.3)                │
└─────────────────────────────────┘
    ↓
┌─────────────────────────────────┐
│  Dense Layer 2 (64 units)      │  ← עוד עיבוד
│  - ReLU activation              │
│  - Dropout (0.3)                │
└─────────────────────────────────┘
    ↓
┌─────────────────────────────────┐
│  Output Layer (8 classes)      │  ← הסתברויות לכל מילה
│  - Softmax activation           │
└─────────────────────────────────┘
    ↓
Output: [0.05, 0.80, 0.10, 0.02, 0.01, 0.01, 0.00, 0.01]
        HELLO  YES   NO   ...  ← "YES" עם 80% confidence
```

---

## למה GRU ולא מודלים אחרים?

### השוואה:

| מודל | יתרונות | חסרונות | מתאים ל- |
|------|---------|---------|----------|
| **GRU** ✅ | מהיר, יעיל, טוב ל-sequences | פחות מורכב מ-Transformer | **תנועות קצרות** |
| LSTM | זוכר טוב יותר | איטי יותר, מסובך יותר | תנועות ארוכות |
| Transformer | חזק מאוד | דורש הרבה נתונים, יקר | תנועות מורכבות |
| CNN | מהיר | לא מבין sequences | תמונות בודדות |

**למה GRU?**
- תנועות שפת סימנים הן **sequences קצרים-בינוניים** (10-100 frames)
- GRU מספיק חזק לזה
- מהיר יותר מ-LSTM
- לא דורש הרבה נתונים כמו Transformer

---

## איך המודל לומד?

### תהליך האימון:

1. **Input**: Sequence של keypoints (30 frames של תנועת "HELLO")
2. **GRU עובד**: עובר על כל frame, זוכר מידע מתנועות קודמות
3. **Output**: הסתברויות - [0.05, 0.80, 0.10, ...] = "YES" עם 80%
4. **Loss**: משווה ל-label האמיתי ("HELLO")
5. **Backpropagation**: מעדכן את המשקולות
6. **חוזר**: על כל הסרטונים ב-dataset

### Loss Function:
- **Sparse Categorical Crossentropy** - מתאים למיון (classification)
- מחשב את ההבדל בין החיזוי ל-label האמיתי

### Optimizer:
- **Adam** - optimizer מתקדם, מתאים לרוב המקרים
- Learning Rate: 0.001 (ברירת מחדל)

---

## פרמטרים של המודל

### ברירת מחדל:

```python
gru_units = 128          # מספר יחידות בכל GRU layer
num_gru_layers = 2       # מספר שכבות GRU
dropout_rate = 0.3       # Dropout (מונע overfitting)
learning_rate = 0.001    # Learning rate
batch_size = 32          # גודל batch
```

### אפשר לשנות:

```bash
python scripts/train_model.py \
    --gru-units 256 \           # יותר יחידות = יותר כוח
    --num-gru-layers 3 \        # יותר שכבות = יותר מורכבות
    --dropout 0.5 \             # יותר dropout = פחות overfitting
    --learning-rate 0.0001      # יותר איטי = יותר מדויק
```

---

## איך המודל מזהה מילה?

### תהליך החיזוי:

```
1. סרטון חדש
   ↓
2. חילוץ keypoints (MediaPipe)
   ↓
3. נרמול keypoints
   ↓
4. הכנה: (sequence_length, 126 features)
   ↓
5. המודל עובד:
   - GRU Layer 1: עובר על כל frame, זוכר מידע
   - GRU Layer 2: עיבוד נוסף
   - Dense Layers: עיבוד סופי
   - Output: הסתברויות
   ↓
6. תוצאה: "HELLO" עם 85% confidence
```

### דוגמה:

**Input**: סרטון של אדם אומר "HELLO" בשפת סימנים

**Processing**:
- Frame 1: יד מתחילה לזוז
- Frame 2-10: תנועת "HELLO"
- Frame 11-15: סיום התנועה

**GRU זוכר**:
- איך התנועה התחילה
- איך היא התפתחה
- איך היא הסתיימה

**Output**: 
```
HELLO: 0.85 (85%)
YES:   0.10 (10%)
NO:    0.03 (3%)
...
```

**תוצאה**: המודל מזהה "HELLO"!

---

## למה זה עובד טוב?

### 1. GRU זוכר מידע מתנועות קודמות

```
Frame 1: יד מתחילה לזוז
Frame 2: יד ממשיכה (GRU זוכר מ-Frame 1)
Frame 3: יד מגיעה לשיא (GRU זוכר מ-Frame 1+2)
...
```

### 2. נרמול מבטיח עקביות

- לא משנה איפה היד בסרטון
- לא משנה איזו יד (שמאל/ימין)
- לא משנה גודל היד

### 3. Sequences מתאימים לתנועות

- תנועות שפת סימנים הן **sequences של תנועות**
- GRU בדיוק מתאים לזה!

---

## שיפורים אפשריים

אם המודל לא מספיק טוב, אפשר:

1. **להגדיל את המודל**:
   ```bash
   --gru-units 256 --num-gru-layers 3
   ```

2. **לנסות LSTM** (זוכר טוב יותר):
   - יותר מורכב, אבל יכול להיות טוב יותר

3. **לנסות Transformer** (אם יש הרבה נתונים):
   - חזק מאוד, אבל דורש הרבה נתונים

4. **להגדיל את ה-dataset**:
   - יותר סרטונים = מודל טוב יותר

---

## סיכום

**המודל: GRU (Gated Recurrent Unit)**

**למה GRU?**
- ✅ מתאים ל-sequences של תנועות
- ✅ מהיר ויעיל
- ✅ לא דורש הרבה נתונים
- ✅ קל לאימון

**איך זה עובד?**
1. חילוץ keypoints מהסרטון
2. נרמול (מיקום, גודל, צד, כיוון)
3. GRU עובד על sequence
4. Output: הסתברויות לכל מילה

**תוצאה**: המודל מזהה מילים בשפת סימנים מסרטונים!

---

**רוצה לשפר?** נסה לשנות את הפרמטרים או להגדיל את המודל.

