# Sign Language Recognition System

××¢×¨×›×ª ×œ×–×™×”×•×™ ×©×¤×ª ×¡×™×× ×™× ×‘×××¦×¢×•×ª GRU Neural Network.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MAya0M/SignLanguage-Recognition/blob/main/notebooks/SignLanguage_Training.ipynb)

> **××•×˜×•××˜×™ ×œ×—×œ×•×˜×™×Ÿ!** ×¤×©×•×˜ ×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨ ×œ××¢×œ×”, ×‘×—×¨ GPU, ×•-Run all. ×”×›×œ ×™×¢×‘×•×“ ××•×˜×•××˜×™×ª! ğŸš€

## ×”×ª×—×œ×” ××”×™×¨×” - Google Colab

**×”×“×¨×š ×”×§×œ×” ×‘×™×•×ª×¨ ×œ×”×ª×—×™×œ:**

1. ×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨ "Open in Colab" ×œ××¢×œ×” â¬†ï¸
2. Runtime â†’ Change runtime type â†’ Select **GPU**
3. Run all cells (Runtime â†’ Run all)

**×–×” ×”×›×œ!** ×”××•×“×œ ×™×ª×××Ÿ ××•×˜×•××˜×™×ª.

---

## ××‘× ×” ×”×¤×¨×•×™×§×˜

```
SignLanguage-Recognition/
â”œâ”€â”€ Data/                    # × ×ª×•× ×™×
â”‚   â”œâ”€â”€ Keypoints/          # Keypoints ××•×¤×§×™× (.npy files)
â”‚   â”œâ”€â”€ Labels/             # CSV files ×¢× dataset splits
â”‚   â”œâ”€â”€ rawVideos/          # ×¡×¨×˜×•× ×™× ××§×•×¨×™×™×
â”‚   â””â”€â”€ Sessions/           # ×¡×¨×˜×•× ×™ sessions
â”œâ”€â”€ scripts/                # ×¡×§×¨×™×¤×˜×™× ×¢×™×§×¨×™×™×
â”‚   â”œâ”€â”€ extract_keypoints.py      # ×—×™×œ×•×¥ keypoints ××¡×¨×˜×•× ×™×
â”‚   â”œâ”€â”€ create_dataset_csv.py     # ×™×¦×™×¨×ª CSV dataset
â”‚   â”œâ”€â”€ train_model.py            # ××™××•×Ÿ ××•×“×œ GRU
â”‚   â”œâ”€â”€ predict.py                # ×—×™×–×•×™ ××¡×¨×˜×•× ×™×
â”‚   â”œâ”€â”€ data_loader.py            # ×˜×¢×™× ×ª × ×ª×•× ×™×
â”‚   â””â”€â”€ model_gru.py              # ××¨×›×™×˜×§×˜×•×¨×ª ××•×“×œ
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”‚   â””â”€â”€ SignLanguage_Training.ipynb  # Colab notebook ××•×˜×•××˜×™
â”œâ”€â”€ docs/                   # ×ª×™×¢×•×“
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ README_MODEL.md
â”‚   â”œâ”€â”€ COLAB_UPLOAD_GUIDE.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                 # ××•×“×œ×™× ×××•×× ×™×
â”œâ”€â”€ output/                 # ×¤×œ×˜×™× (annotated videos, etc.)
â”œâ”€â”€ utils/                  # ×›×œ×™ ×¢×–×¨
â””â”€â”€ requirements.txt        # ×ª×œ×•×™×•×ª Python
```

---

## ×”×ª×§× ×” ××§×•××™×ª

### 1. Clone Repository

```bash
git clone https://github.com/MAya0M/SignLanguage-Recognition.git
cd SignLanguage-Recognition
```

### 2. ×”×ª×§×Ÿ ×ª×œ×•×™×•×ª

```bash
# ×™×¦×™×¨×ª virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# ×”×ª×§× ×ª ×ª×œ×•×™×•×ª
pip install -r requirements.txt
```

---

## ×©×™××•×©

### Google Colab (××•××œ×¥!) â­

**×”×“×¨×š ×”×›×™ ×§×œ×”:**
1. ×œ×—×¥ ×¢×œ [Open in Colab](https://colab.research.google.com/github/MAya0M/SignLanguage-Recognition/blob/main/notebooks/SignLanguage_Training.ipynb)
2. Runtime â†’ Change runtime type â†’ **GPU**
3. Run all cells

**××•:**
1. ×¤×ª×— [Google Colab](https://colab.research.google.com)
2. File â†’ Open notebook â†’ GitHub
3. ×”×–×Ÿ: `MAya0M/SignLanguage-Recognition`
4. ×‘×—×¨: `notebooks/SignLanguage_Training.ipynb`

### ××§×•××™ (×× ×™×© GPU)

```bash
# 1. ×—×™×œ×•×¥ keypoints
python scripts/extract_keypoints.py

# 2. ×™×¦×™×¨×ª dataset
python scripts/create_dataset_csv.py

# 3. ××™××•×Ÿ ×”××•×“×œ
python scripts/train_model.py --csv Data/Labels/dataset.csv

# 4. ×—×™×–×•×™
python scripts/predict.py \
    --model models/run_*/best_model.keras \
    --video your_video.mp4
```

---

## ×ª×›×•× ×•×ª ×¢×™×§×¨×™×•×ª

âœ… **× ×¨××•×œ ××ª×§×“×** - ×‘×œ×ª×™ ×ª×œ×•×™ ×‘××™×§×•× ×”×™×“, ×’×•×“×œ ×”×™×“, ×•×¦×“ ×”×™×“ (×©×××œ/×™××™×Ÿ)  
âœ… **Google Colab** - GPU ×—×™× ×, ××™××•×Ÿ ××•×˜×•××˜×™  
âœ… **××•×“×œ GRU** - ×œ×–×™×”×•×™ sequences ×©×œ ×ª× ×•×¢×•×ª ×™×“  
âœ… **×—×™×–×•×™ ××¡×¨×˜×•× ×™×** - ×—×™×–×•×™ ×™×©×™×¨×•×ª ××¡×¨×˜×•× ×™× ××• keypoints  
âœ… **××¤×œ×™×§×¦×™×™×ª Web** - ×”×¢×œ×” ×¡×¨×˜×•×Ÿ ×•×§×‘×œ ×ª×¨×’×•× ×“×¨×š ×“×¤×“×¤×Ÿ! ğŸ¬  

---

## ×ª×™×¢×•×“

- **[××“×¨×™×š ××•×“×œ](docs/README_MODEL.md)** - ×¤×¨×˜×™× ×¢×œ ×”××•×“×œ ×•×”××™××•×Ÿ
- **[××“×¨×™×š Colab](docs/COLAB_UPLOAD_GUIDE.md)** - ××™×š ×œ×”×¢×œ×•×ª × ×ª×•× ×™× ×œ-Colab
- **[××“×¨×™×š ×™×™×©×•×](docs/IMPLEMENTATION_GUIDE.md)** - ××“×¨×™×š ×™×™×©×•× ××œ×
- **[×”×¡×‘×¨ ××•×“×œ](docs/MODEL_EXPLANATION.md)** - ××™×š ×”××•×“×œ ×¢×•×‘×“
- **[××“×¨×™×š ××¤×œ×™×§×¦×™×”](docs/APP_GUIDE.md)** - ××¤×œ×™×§×¦×™×™×ª Web ×œ×”×¢×œ××ª ×¡×¨×˜×•× ×™×
- **[README ××¤×œ×™×§×¦×™×”](README_APP.md)** - ×”×ª×—×œ×” ××”×™×¨×” ×œ××¤×œ×™×§×¦×™×”

---

## Workflow ××œ×

```bash
# 1. ×—×™×œ×•×¥ keypoints
python scripts/extract_keypoints.py

# 2. ×™×¦×™×¨×ª dataset
python scripts/create_dataset_csv.py

# 3. ××™××•×Ÿ (Google Colab ××•××œ×¥!)
# ×œ×—×¥ ×¢×œ "Open in Colab" ×œ××¢×œ×”

# 4. ×”×¨×¦×ª ××¤×œ×™×§×¦×™×™×ª Web
python app.py
# ×¤×ª×— http://localhost:5000 ×•×”×¢×œ×” ×¡×¨×˜×•×Ÿ!

# ××• ×—×™×–×•×™ ×“×¨×š command line
python scripts/predict.py --model models/.../best_model.keras --video test.mp4
```

---

## ×“×¨×™×©×•×ª

- Python 3.8+
- GPU (××•××œ×¥ ×œ××™××•×Ÿ) - Google Colab ××¡×¤×§ GPU ×—×™× ×!
- ~10GB disk space
- MediaPipe Hand Landmarker model (××•×¨×“ ××•×˜×•××˜×™×ª)

---

## ×¨×™×©×™×•×Ÿ

×¤×¨×•×™×§×˜ ×–×” ×”×•× ×œ××˜×¨×•×ª ×œ×™××•×“.

---

## ×ª××™×›×”

×œ×©××œ×•×ª ×•×‘×¢×™×•×ª, ×¨××” ××ª ×”××“×¨×™×›×™× ×‘-`docs/`.

---

**×‘×”×¦×œ×—×”! ğŸš€**
