# Sign Language Recognition System

Sign language recognition system using GRU Neural Network.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MAya0M/SignLanguage-Recognition/blob/main/notebooks/SignLanguage_Training.ipynb)

> **Fully Automatic!** Just click the button above, select GPU, and Run all. Everything will work automatically! ğŸš€

> **âœ… Production Ready!** The app is tested and deployed on Railway. All dependencies are configured for cloud deployment.

## ğŸš€ Quick Start

### Option 1: Use Online App (Recommended!)

**The app is ready to deploy!** Follow these steps:

1. **Deploy to Railway (Free):**
   - Go to [railway.app](https://railway.app)
   - Sign in with GitHub
   - Click "New Project" â†’ "Deploy from GitHub repo"
   - Select this repository
   - Railway will auto-detect Flask app
   - Click "Deploy" - **That's it!**
   - Your app will be live at: `https://your-app-name.railway.app`

2. **Or Deploy to Render (Free):**
   - Go to [render.com](https://render.com)
   - Sign in with GitHub
   - Click "New" â†’ "Web Service"
   - Select this repository
   - Build Command: `pip install -r requirements.txt`
   - Start Command: `gunicorn app:app`
   - Click "Create Web Service"

**See [docs/DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md) for detailed instructions.**

### Option 2: Train Model in Google Colab

1. Click the "Open in Colab" button above â¬†ï¸
2. Runtime â†’ Change runtime type â†’ Select **GPU**
3. Run all cells (Runtime â†’ Run all)

**That's it!** The model will train automatically.

---

## Project Structure

```
SignLanguage-Recognition/
â”œâ”€â”€ Data/                    # Data
â”‚   â”œâ”€â”€ Keypoints/          # Extracted keypoints (.npy files)
â”‚   â”œâ”€â”€ Labels/             # CSV files with dataset splits
â”‚   â”œâ”€â”€ rawVideos/          # Original videos
â”‚   â””â”€â”€ Sessions/           # Session videos
â”œâ”€â”€ scripts/                # Main scripts
â”‚   â”œâ”€â”€ extract_keypoints.py      # Extract keypoints from videos
â”‚   â”œâ”€â”€ create_dataset_csv.py     # Create CSV dataset
â”‚   â”œâ”€â”€ train_model.py            # Train GRU model
â”‚   â”œâ”€â”€ predict.py                # Predict from videos
â”‚   â”œâ”€â”€ data_loader.py            # Data loading
â”‚   â””â”€â”€ model_gru.py              # Model architecture
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”‚   â””â”€â”€ SignLanguage_Training.ipynb  # Automatic Colab notebook
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ README_MODEL.md
â”‚   â”œâ”€â”€ COLAB_UPLOAD_GUIDE.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                 # Trained models
â”œâ”€â”€ output/                 # Outputs (annotated videos, etc.)
â”œâ”€â”€ utils/                  # Utilities
â””â”€â”€ requirements.txt        # Python dependencies
```

---

## Local Installation

### 1. Clone Repository

```bash
git clone https://github.com/MAya0M/SignLanguage-Recognition.git
cd SignLanguage-Recognition
```

### 2. Install Dependencies

```bash
# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

---

## Usage

### Google Colab (Recommended!) â­

**The easiest way:**
1. Click [Open in Colab](https://colab.research.google.com/github/MAya0M/SignLanguage-Recognition/blob/main/notebooks/SignLanguage_Training.ipynb)
2. Runtime â†’ Change runtime type â†’ **GPU**
3. Run all cells

**Or:**
1. Open [Google Colab](https://colab.research.google.com)
2. File â†’ Open notebook â†’ GitHub
3. Enter: `MAya0M/SignLanguage-Recognition`
4. Select: `notebooks/SignLanguage_Training.ipynb`

### Local (if you have GPU)

```bash
# 1. Extract keypoints
python scripts/extract_keypoints.py

# 2. Create dataset
python scripts/create_dataset_csv.py

# 3. Train model
python scripts/train_model.py --csv Data/Labels/dataset.csv

# 4. Run web app
python app.py
# Open http://localhost:5000 and upload a video!

# Or predict via command line
python scripts/predict.py \
    --model models/run_*/best_model.keras \
    --video your_video.mp4
```

---

## Features

âœ… **Web Application** - Upload video and get translation through browser! ğŸ¬ **[Deploy Online Now!](#-quick-start)**  
âœ… **Advanced Normalization** - Invariant to hand position, size, and hand side (left/right)  
âœ… **Google Colab** - Free GPU, automatic training  
âœ… **GRU Model** - For recognizing sequences of hand movements  
âœ… **Video Prediction** - Predict directly from videos or keypoints  
âœ… **Automatic CI/CD** - GitHub Actions validates code on every push  
âœ… **Automatic Deployment Ready** - One-click deploy to Railway/Render/Heroku  

---

## Documentation

- **[Model Guide](docs/README_MODEL.md)** - Model details and training
- **[Colab Guide](docs/COLAB_UPLOAD_GUIDE.md)** - How to upload data to Colab
- **[Implementation Guide](docs/IMPLEMENTATION_GUIDE.md)** - Full implementation guide
- **[Model Explanation](docs/MODEL_EXPLANATION.md)** - How the model works
- **[Web App Guide](docs/APP_GUIDE.md)** - Web application for uploading videos
- **[App README](README_APP.md)** - Quick start for the app
- **[GitHub Actions Guide](docs/GITHUB_ACTIONS_EXPLAINED.md)** - What happens after workflow completes
- **[Deployment Guide](docs/DEPLOYMENT_GUIDE.md)** - Deploy to production

---

## Workflow

```bash
# 1. Extract keypoints
python scripts/extract_keypoints.py

# 2. Create dataset
python scripts/create_dataset_csv.py

# 3. Train (Google Colab recommended!)
# Click "Open in Colab" above

# 4. Run web app
python app.py
# Open http://localhost:5000 and upload a video!

# Or predict via command line
python scripts/predict.py --model models/.../best_model.keras --video test.mp4
```

---

## Requirements

- Python 3.8+
- GPU (recommended for training) - Google Colab provides free GPU!
- ~10GB disk space
- MediaPipe Hand Landmarker model (downloaded automatically)

---

## License

This project is for educational purposes.

---

## Support

For questions and issues, see the guides in `docs/`.

---

## GitHub Actions

Every push to GitHub automatically triggers:
- âœ… Syntax checking
- âœ… Import checking
- âœ… Project structure validation

For more details: see [docs/GITHUB_ACTIONS_EXPLAINED.md](docs/GITHUB_ACTIONS_EXPLAINED.md)

## ğŸŒ View App Online

**Your app is ready to deploy!** Get it online in 5 minutes:

### Quick Deploy (Railway - Recommended):
1. Go to [railway.app](https://railway.app) â†’ Sign in with GitHub
2. New Project â†’ Deploy from GitHub repo
3. Select this repository â†’ Deploy
4. **Done!** Your app will be live at `https://your-app.railway.app`

**See [docs/QUICK_DEPLOY.md](docs/QUICK_DEPLOY.md) for step-by-step instructions.**

### Other Options:
- **Render:** [render.com](https://render.com) - Free tier available
- **Heroku:** [heroku.com](https://heroku.com) - Free tier available

**Note:** Make sure to train a model first! See [Training Guide](docs/README_MODEL.md) or use [Google Colab](https://colab.research.google.com/github/MAya0M/SignLanguage-Recognition/blob/main/notebooks/SignLanguage_Training.ipynb).

---

**Good luck! ğŸš€**
