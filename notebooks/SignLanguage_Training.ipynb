{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sign Language Recognition - Training Notebook\n",
        "\n",
        "This notebook automatically trains the GRU model for sign language recognition.\n",
        "\n",
        "## Quick Start:\n",
        "1. **Runtime → Change runtime type → Select GPU**\n",
        "2. **Runtime → Run all**\n",
        "\n",
        "Or click the \"Open in Colab\" badge in the GitHub repository!\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** Make sure your data is available in the `Data/` directory. If you need to upload data, see `docs/COLAB_UPLOAD_GUIDE.md`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/MAya0M/SignLanguage-Recognition.git\n",
        "%cd SignLanguage-Recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q tensorflow numpy pandas scikit-learn opencv-python mediapipe tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Data\n",
        "\n",
        "Make sure your data is in the `Data/` directory. If not, upload it using one of the methods in `docs/COLAB_UPLOAD_GUIDE.md`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data exists\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "data_dir = Path('Data')\n",
        "if data_dir.exists():\n",
        "    print(\"✅ Data directory found\")\n",
        "    csv_path = data_dir / 'Labels' / 'dataset.csv'\n",
        "    keypoints_dir = data_dir / 'Keypoints' / 'rawVideos'\n",
        "    if csv_path.exists():\n",
        "        print(f\"✅ CSV file: {csv_path}\")\n",
        "    else:\n",
        "        print(f\"❌ CSV file not found: {csv_path}\")\n",
        "    if keypoints_dir.exists():\n",
        "        print(f\"✅ Keypoints directory: {keypoints_dir}\")\n",
        "    else:\n",
        "        print(f\"❌ Keypoints directory not found: {keypoints_dir}\")\n",
        "else:\n",
        "    print(\"❌ Data directory not found\")\n",
        "    print(\"Please upload data first! See docs/COLAB_UPLOAD_GUIDE.md\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "!python scripts/train_model.py \\\n",
        "    --csv Data/Labels/dataset.csv \\\n",
        "    --keypoints-dir Data/Keypoints/rawVideos \\\n",
        "    --output-dir models \\\n",
        "    --batch-size 32 \\\n",
        "    --epochs 100 \\\n",
        "    --gru-units 128 \\\n",
        "    --num-gru-layers 2 \\\n",
        "    --dropout 0.3 \\\n",
        "    --learning-rate 0.001 \\\n",
        "    --patience 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List trained models\n",
        "import glob\n",
        "models = glob.glob('models/run_*/best_model.keras')\n",
        "if models:\n",
        "    print(\"✅ Trained models:\")\n",
        "    for model in sorted(models):\n",
        "        print(f\"  - {model}\")\n",
        "else:\n",
        "    print(\"❌ No models found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Model (Optional)\n",
        "\n",
        "To save your trained model to Google Drive:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download to Google Drive (optional)\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "models_dir = sorted(glob.glob('models/run_*'))\n",
        "if models_dir:\n",
        "    latest_run = models_dir[-1]  # Latest run\n",
        "    dest = f'/content/drive/MyDrive/{Path(latest_run).name}'\n",
        "    shutil.copytree(latest_run, dest, dirs_exist_ok=True)\n",
        "    print(f\"✅ Model saved to Google Drive: {Path(latest_run).name}\")\n",
        "else:\n",
        "    print(\"❌ No models found\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
